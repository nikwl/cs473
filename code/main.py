# -*- coding: utf-8 -*-
"""DeepLearning2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1auOKfyPPUtwZn-Ak2tCefsEhHvmG1rT7
"""

# Google drive access
from google.colab import drive
drive.mount('/content/drive')

import os
# View the location of the shared google drive folder
img_dir = "/content/drive/MyDrive/Classes/cs473"
print(os.listdir(img_dir))

from torch.utils.data import Dataset, DataLoader

import pickle
import numpy as np

class MyDataset(Dataset):
  def __init__(self, data, transforms=None, target_transforms=None):
    self.transforms = transforms
    self.target_transforms = target_transforms
    self.data, self.labels = pickle.load(open(data, "rb"))
    print(f"Loaded {len(self.data)} samples!")

  def __len__(self):
    return len(self.data)

  def __getitem__(self, index):
    img = self.data[index]
    label = self.labels[index]

    # label is of the form: "...-{}-....png"
    label = label.split("-")[1]
    label = int(label)

    # Transpose so image channels come first
    img = np.transpose(img, (2, 0, 1))
    img = img.astype(np.float32)

    if self.transforms is not None:
      img = self.transforms(img)
    if self.target_transforms is not None:
      label = self.target_transforms(label)

    return img, label

import torch.nn as nn

class MyNet(nn.Module):
  def __init__(self):
    super(MyNet, self).__init__()

    self.conv1 = nn.Conv2d(
        in_channels=3,
        out_channels=32,
        kernel_size=3,
    ) # output size: (batch_size, 32, 30, 30)

    self.maxpool1 = nn.MaxPool2d(
        kernel_size=2
    ) # output size: (batch_size, 32, 15, 15)

    self.conv2 = nn.Conv2d(
        in_channels=32,
        out_channels=64,
        kernel_size=3,
    ) # output size: (batch_size, 64, 13, 13)

    self.maxpool2 = nn.MaxPool2d(
        kernel_size=2,
    ) # output size: (batch_size, 64, 6, 6)

    self.fc1 = nn.Linear(
        in_features=(64*6*6),
        out_features=10,
    )
    self.softmax = nn.LogSoftmax(
        dim=1,
    )
    self.relu = nn.ReLU()

  def forward(self, x):
    x = self.conv1(x)
    x = self.relu(x)
    x = self.maxpool1(x)
    # print(x.shape)
    x = self.conv2(x)
    x = self.relu(x)
    x = self.maxpool2(x)
    # print(x.shape)
    x = torch.flatten(x, 1)
    x = self.fc1(x)
    x = self.softmax(x)
    return x

import torch 
import torch.optim as optim

def train(dataloader, model, epoch, optmizer, device):
  model.train() # activates training mode
  loss_fn = nn.NLLLoss()
  for i, (data, label) in enumerate(dataloader):
    optimizer.zero_grad()
    data, label = data.to(device), label.to(device) 
    pred = model(data)
    loss = loss_fn(pred, label)
    loss.backward()
    optmizer.step()

    if i % 10 == 0:
      print(f"Loss for epoch {epoch} is {loss.item()}")
    
# Code to actually train our network
lr = 0.01
epochs = 16
batch_size = 128

dataset = MyDataset("/content/drive/MyDrive/Classes/cs473/data2.pkl", None, None)
dataloader = DataLoader(dataset, batch_size=batch_size)

import matplotlib.pyplot as plt
import torchvision

def show_image(img):
  img = img.numpy()
  img = np.transpose(img, (1, 2, 0))
  img = img.astype(np.uint8)
  plt.imshow(img)

data, labels = next(iter(dataloader))
images = torchvision.utils.make_grid(data)
show_image(images)

model = MyNet()

device = torch.device("cpu")
if torch.cuda.is_available():
  device = torch.device("cuda")

model.to(device)

optimizer = optim.Adam(params=model.parameters(), lr=lr)

for epoch in range(epochs):
  train(dataloader, model, epoch, optimizer, device)

torch.save(model.state_dict(), "model.pt")
model.load_state_dict(torch.load("model.pt"))